{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pirKNXxZk2Bd"
   },
   "source": [
    "**Libraries**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1719171760030,
     "user": {
      "displayName": "Hajar El Hassani",
      "userId": "04871212387096863719"
     },
     "user_tz": -120
    },
    "id": "PATezzl4kmFw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pr1EnoQk_nr"
   },
   "source": [
    "**MDP class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1719171761724,
     "user": {
      "displayName": "Hajar El Hassani",
      "userId": "04871212387096863719"
     },
     "user_tz": -120
    },
    "id": "vJ8BrmeJk0X8"
   },
   "outputs": [],
   "source": [
    "# MDP class\n",
    "# The class takes four parameters: transition_probs, rewards, initial_state, and terminal_states.\n",
    "\n",
    "# transition_probs: dictionary that defines the probabilities of transitioning from one state to another given a certain action.\n",
    "# rewards: dictionary that specifies the rewards received when transitioning from one state to another using a particular action.\n",
    "# initial_state: starting state of the MDP.\n",
    "# terminal_states: list of states that are considered terminal, meaning the process ends when these states are reached.\n",
    "\n",
    "class MDP:\n",
    "    def __init__(self, transition_probs, rewards, initial_state, terminal_states=None):\n",
    "        self.transition_probs = transition_probs\n",
    "        self.rewards = rewards\n",
    "        self.initial_state = initial_state\n",
    "        self.state = initial_state\n",
    "        self.terminal_states = terminal_states if terminal_states else []\n",
    "\n",
    "    def get_all_states(self):\n",
    "        return list(self.transition_probs.keys())\n",
    "\n",
    "    def get_possible_actions(self, state):\n",
    "        return list(self.transition_probs[state].keys())\n",
    "\n",
    "    def get_next_states(self, state, action):\n",
    "        return self.transition_probs[state][action]\n",
    "\n",
    "    def get_transition_prob(self, state, action, next_state):\n",
    "        return self.transition_probs[state][action].get(next_state, 0) # Returns 0 if next_state is not found.\n",
    "\n",
    "    def get_reward(self, state, action, next_state):\n",
    "        return self.rewards.get(state, {}).get(action, {}).get(next_state, 0)\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.initial_state\n",
    "        return self.state\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        return state in self.terminal_states\n",
    "\n",
    "    def get_next_state(self, state, action):\n",
    "        next_states = self.transition_probs[state][action]\n",
    "        next_state = max(next_states, key=next_states.get)\n",
    "        return next_state\n",
    "\n",
    "    def step(self, action):\n",
    "        next_states_probs = self.transition_probs[self.state][action]\n",
    "        next_states = list(next_states_probs.keys())\n",
    "        probabilities = list(next_states_probs.values())\n",
    "        next_state = np.random.choice(next_states, p=probabilities)\n",
    "        reward = self.get_reward(self.state, action, next_state)\n",
    "        self.state = next_state\n",
    "        done = self.is_terminal(next_state)\n",
    "        return next_state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AFdD8-vlXwz"
   },
   "source": [
    "**Define the transition probabilities and rewards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1719171764744,
     "user": {
      "displayName": "Hajar El Hassani",
      "userId": "04871212387096863719"
     },
     "user_tz": -120
    },
    "id": "5hMOiBfBldtE"
   },
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.6, 's1': 0.4},\n",
    "        'a1': {'s1': 0.8, 's2': 0.2}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.3, 's2': 0.7},\n",
    "        'a1': {'s2': 1.0}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s1': 0.5, 's2': 0.5},\n",
    "        'a1': {'s0': 0.3, 's2': 0.7}\n",
    "    }\n",
    "}\n",
    "\n",
    "rewards = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0, 's1': 0},\n",
    "        'a1': {'s1': 2, 's2': 0}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0, 's2': 3},\n",
    "        'a1': {'s2': 0}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s1': 0, 's2': 0},\n",
    "        'a1': {'s0': -2, 's2': 0}\n",
    "    }\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards['s0']['a1']['s1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lRakc9TnRZB"
   },
   "source": [
    "**Getting familiar with MDP class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yz_T2yFqnTnF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All states: ['s0', 's1', 's2']\n",
      "Possible actions from 's0': ['a0', 'a1']\n",
      "Next states for action 'a0' from state 's0': {'s0': 0.6, 's1': 0.4}\n",
      "Transition probability from 's0' to 's1' with action 'a0': 0.4\n",
      "Reward from 's0' to 's1' with action 'a0': 0\n",
      "Current state: s1\n"
     ]
    }
   ],
   "source": [
    "initial_state = 's0'\n",
    "terminal_states = ['s2']\n",
    "\n",
    "# Create the MDP instance\n",
    "mdp = MDP(transition_probs, rewards, initial_state, terminal_states)\n",
    "\n",
    "# Get all states\n",
    "all_states = mdp.get_all_states()\n",
    "print(f\"All states: {all_states}\")\n",
    "\n",
    "# Get possible actions from state 's0'\n",
    "possible_actions = mdp.get_possible_actions('s0')\n",
    "print(f\"Possible actions from 's0': {possible_actions}\")\n",
    "\n",
    "# Get next states for action 'a0' from state 's0'\n",
    "next_states = mdp.get_next_states('s0', 'a0')\n",
    "print(f\"Next states for action 'a0' from state 's0': {next_states}\")\n",
    "\n",
    "# Get transition probability from 's0' to 's1' with action 'a0'\n",
    "transition_prob = mdp.get_transition_prob('s0', 'a0', 's1')\n",
    "print(f\"Transition probability from 's0' to 's1' with action 'a0': {transition_prob}\")\n",
    "\n",
    "# Get the reward of transitioning from state to next state by taking action\n",
    "reward = mdp.get_reward('s0', 'a0', 's1')\n",
    "print(f\"Reward from 's0' to 's1' with action 'a0': {reward}\")\n",
    "\n",
    "state,reward, done = mdp.step('a0')\n",
    "print(f\"Current state: {mdp.state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxAgBrwowG_"
   },
   "source": [
    "# **Solving the MDP with Value Iteration algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1719171786105,
     "user": {
      "displayName": "Hajar El Hassani",
      "userId": "04871212387096863719"
     },
     "user_tz": -120
    },
    "id": "MrdwfhAInSAK"
   },
   "outputs": [],
   "source": [
    "def initialize_value_function(states):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      states: list of all states in the MDP.\n",
    "\n",
    "    Returns:\n",
    "      dict: dictionary with states as keys and 0 as initial values.\n",
    "    \"\"\"\n",
    "    init_states = {}\n",
    "    keys = mdp.get_all_states()\n",
    "    values = np.zeros(len(keys))\n",
    "    init_states = dict(zip(keys, values))\n",
    "    return init_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s0': 0.0, 's1': 0.0, 's2': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_states = initialize_value_function(all_states)\n",
    "print(init_states)\n",
    "max(init_states.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rUbAAQRonaJ4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s0': 1.6, 's1': 2.5319999999999996, 's2': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_value_function(mdp, value_function, discount_factor):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      mdp: your mdp instance.\n",
    "      value_function: current value function.\n",
    "      discount_factor: discount factor for future rewards.\n",
    "\n",
    "    Returns:\n",
    "      dict: updated value function.\n",
    "    \"\"\"\n",
    "    new_value_function = value_function.copy()\n",
    "\n",
    "    for state in mdp.get_all_states():\n",
    "        if not mdp.is_terminal(state):\n",
    "            max_value = float('-inf')\n",
    "            for action in mdp.get_possible_actions(state):\n",
    "                # initialize the expected value: YOUR CODE HERE\n",
    "                expected_value = 0\n",
    "                for next_state in mdp.get_next_states(state, action):  \n",
    "                    #transition_prob = YOUR CODE HERE\n",
    "                    transition_prob = mdp.get_transition_prob(state,action,next_state)\n",
    "                    #reward = YOUR CODE HERE\n",
    "                    reward = mdp.get_reward(state,action,next_state)\n",
    "                    #expected_value = YOUR CODE HERE\n",
    "                    expected_value += transition_prob*(reward+discount_factor*new_value_function[next_state])\n",
    "                #max_value = YOUR CODE \n",
    "\n",
    "                max_value = max(expected_value,max_value)\n",
    "            new_value_function[state] = max_value\n",
    "\n",
    "    return new_value_function\n",
    "initial_state=initialize_value_function(all_states)\n",
    "update_value_function(mdp,initial_state,0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = MDP(transition_probs, rewards, initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VgPXDDAHncFZ"
   },
   "outputs": [],
   "source": [
    "def value_iteration(mdp, discount_factor, threshold):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      mdp: your mdp instance.\n",
    "      discount_factor: discount factor for future rewards.\n",
    "      threshold: threshold for convergence.\n",
    "\n",
    "    Returns:\n",
    "      dict: optimal value function.\n",
    "      list: history of value functions over iterations.\n",
    "    \"\"\"\n",
    "    # initialize the value function: YOUR CODE HERE\n",
    "    value_function = initialize_value_function(mdp)\n",
    "    # iterate until convergence\n",
    "    # YOUR CODE HERE\n",
    "    history = []\n",
    "    difference = 1\n",
    "    count = 0\n",
    "    while difference> threshold:\n",
    "\n",
    "      new_value_function = update_value_function(mdp,value_function,discount_factor)\n",
    "      history.append(new_value_function)\n",
    "      count+=1\n",
    "      difference = abs(sum(new_value_function.values())-sum(value_function.values()))\n",
    "      value_function = new_value_function\n",
    "    return value_function, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "{'s0': 10.353911591169746, 's1': 10.09697976060065, 's2': 8.258943485830878}\n"
     ]
    }
   ],
   "source": [
    "value_function,history=value_iteration(mdp,0.9,0.01)\n",
    "print(len(history))\n",
    "print(history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1448aaaecc0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s0_list=[step['s0'] for step in history]\n",
    "s1_list=[step['s1'] for step in history]\n",
    "s2_list=[step['s2'] for step in history]\n",
    "x = np.arange(0,len(s0_list))\n",
    "plt.plot(x,s0_list,'r')\n",
    "plt.plot(x,s1_list,'g')\n",
    "plt.plot(x,s2_list,'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvEKucZHoVd5"
   },
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discount factor is used to increase the weight of immediate rewards and penalize rewards obtained after a long time.\n",
    "Its values are between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rEsBGPhoZbP"
   },
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stopping criterion is used to stop the MDP after it reaches convergence. It is still required in practice even if the MDP has a terminal state to stop the MDP if it converges before reaching the terminal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ-VnKzoobno"
   },
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal policy for an MDP is the best action to take for each state.\n",
    "Since the state s0 has the highest reward, the optimal policy should be to return to state s0 if the state is s1 or s2, and go to s1, the second highest reward if the state is s1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xyhYuemqno_s"
   },
   "outputs": [],
   "source": [
    "def get_optimal_policy(mdp, value_function, discount_factor):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      mdp: your MDP instance.\n",
    "      value_function: the converged value function.\n",
    "      discount_factor: discount factor for future rewards.\n",
    "    Returns:\n",
    "      dict: optimal policy.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    new_value_function = value_function.copy()\n",
    "    \n",
    "    policy = {'s0':'a0','s1':'a0','s2':'a0'}\n",
    "    for state in mdp.get_all_states():\n",
    "        if not mdp.is_terminal(state):\n",
    "            max_value = 0\n",
    "            for action in mdp.get_possible_actions(state):\n",
    "                # initialize the expected value: YOUR CODE HERE\n",
    "                expected_value = 0\n",
    "                for next_state in mdp.get_next_states(state, action):  \n",
    "                    #transition_prob = YOUR CODE HERE\n",
    "                    transition_prob = mdp.get_transition_prob(state,action,next_state)\n",
    "                    #reward = YOUR CODE HERE\n",
    "                    reward = mdp.get_reward(state,action,next_state)\n",
    "                    #expected_value = YOUR CODE HERE\n",
    "                    expected_value += transition_prob*(reward+discount_factor*new_value_function[next_state])\n",
    "                if expected_value>max_value:\n",
    "                  policy[state] =action\n",
    "                  max_value=expected_value\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua8lST97oexc"
   },
   "source": [
    "**Question 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s0': 'a1', 's1': 'a0', 's2': 'a0'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_optimal_policy(mdp,history[-1],0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that the best policy is to return to s0 if state is not s0, else go to s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__txIesxogad"
   },
   "source": [
    "**Question 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-gX2sBwoo6D"
   },
   "source": [
    "# **Solving the MDP with Q-learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QasZguK7ojrv"
   },
   "source": [
    "**Question 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Q-learning algorithm estimates the best action to take for each state, whereas the MPD computes the value of each state, it needs complete information. The Q-learning algorithm doesn't need the transition probabilities or rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PGLYXcBo-ym"
   },
   "source": [
    "**Question 7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Q-table gives the expected reward for each action for each state, and is needed to get the action that gives the best expected reward for the given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Oyo9kn0VnzYi"
   },
   "outputs": [],
   "source": [
    "def initialize_q_table(states, actions):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      states: all possible states\n",
    "      actions: all possible actions.\n",
    "\n",
    "    Returns:\n",
    "      dict: Q-table initialized.\n",
    "    \"\"\"\n",
    "    Q = []\n",
    "    for state in states :\n",
    "        for action in actions :\n",
    "            Q.append([state,action,0])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['s0', 'a0', 0],\n",
       " ['s0', 'a1', 0],\n",
       " ['s1', 'a0', 0],\n",
       " ['s1', 'a1', 0],\n",
       " ['s2', 'a0', 0],\n",
       " ['s2', 'a1', 0]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = initialize_q_table(['s0','s1','s2'],['a0','a1'])\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyI56cVApRjg"
   },
   "source": [
    "**Question 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploration step is randomly choosing new actions to discover potential rewards, the exploitation is choosing the best known action to maximize the reward. The eps-greedy algorithm randomly chooses to take an exploration action with a probability of eps, or an expoloitation action with the probability 1-eps. If the eps is too small,  there won't be enough exploration and the algorithm won't be very accurate, if eps is too high, the exploitation will be rare and the algorithm will be very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09621681765341183"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "random.choice([0,1,2])\n",
    "state_index = int(state[1])\n",
    "state_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "0dqGboXKn398"
   },
   "outputs": [],
   "source": [
    "def choose_action(state, Q, epsilon):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      state: current state of the agent.\n",
    "      Q: Q-table.\n",
    "      epsilon: exploration rate.\n",
    "\n",
    "    Returns:\n",
    "      action: chosen action.\n",
    "    \"\"\"\n",
    "    state_index = int(state[1])*2\n",
    "    if random.random()<epsilon : #exploration\n",
    "      rd_act_index = random.choice([0,1])\n",
    "      rd_act = 'a'+str(rd_act_index)\n",
    "      Q[state_index+rd_act_index][2] = max(rewards[state][rd_act].values())\n",
    "      return rd_act\n",
    "    if random.random()>epsilon : #exploitation\n",
    "      max_Q = -10\n",
    "      for act_index in range(0,2):\n",
    "          if Q[state_index+act_index][2]>max_Q:\n",
    "             max_Q = Q[state_index+act_index][2]\n",
    "             action = 'a'+str(act_index)\n",
    "      return action\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,100):\n",
    "    choose_action('s2',Q,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['s0', 'a0', 0],\n",
       " ['s0', 'a1', 2],\n",
       " ['s1', 'a0', 3],\n",
       " ['s1', 'a1', 0],\n",
       " ['s2', 'a0', 0],\n",
       " ['s2', 'a1', 0]]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "next_states=rewards['s0']['a1'].keys()\n",
    "for state in next_states :\n",
    "    print(rewards['s0']['a1'][state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "fsfKEfWrn_SB"
   },
   "outputs": [],
   "source": [
    "def get_next_state_and_reward(state, action):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      state: the current state of the agent.\n",
    "      action: the action taken by the agent.\n",
    "\n",
    "    Returns:\n",
    "      next_state: the next state of the agent.\n",
    "      reward: the reward received for transitioning to the next state.\n",
    "    \"\"\"\n",
    "    next_states = rewards[state][action].keys()\n",
    "    reward = -10\n",
    "    for pot_nxt_stt in next_states : \n",
    "        if rewards[state][action][pot_nxt_stt]>reward:\n",
    "            reward = rewards[state][action][pot_nxt_stt]\n",
    "            next_state = pot_nxt_stt\n",
    "    return next_state,reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SBCy49pFoEZ5"
   },
   "outputs": [],
   "source": [
    "def q_learning(states, actions, transition_probs, rewards, episodes, max_steps_per_episode, alpha, epsilon, gamma):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      states: all possible states.\n",
    "      actions: all possible actions.\n",
    "      transition_probs: transition probabilities.\n",
    "      rewards: rewards for state-action-next_state transitions.\n",
    "      episodes: number of episodes to run.\n",
    "      max_steps_per_episode: maximum steps per episode.\n",
    "      alpha: learning rate.\n",
    "      epsilon: exploration rate.\n",
    "      gamma: discount factor.\n",
    "\n",
    "    Returns:\n",
    "      Q: The learned Q-table.\n",
    "      policy: The optimal policy derived from the Q-table.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuw_SMEapV33"
   },
   "source": [
    "**Question 9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHiMfcHxpfrq"
   },
   "source": [
    "**Question 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "q1EL28jAoJ2x"
   },
   "outputs": [],
   "source": [
    "# Plot the average rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84jUc9KApoCu"
   },
   "source": [
    "**Question 11**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42LKXBZappkI"
   },
   "source": [
    "**Question 12**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNFel3g/kGEJ4MDbOJCRccK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
